{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2570961b-b58d-43a4-b848-ef51acad468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "collection = chroma_client.get_or_create_collection(\"Biography\")\n",
    "collection.add(\n",
    "    documents=[\"My name is John.\", \"My job is coding.\", \"My dog's name is Fido. Fido is an expert fetcher.\"],\n",
    "    ids=[\"id1\", \"id2\", \"id3\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05b8e2e1-7cc7-4673-b91a-1a55f5602aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from literalai import LiteralClient\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "literal_client = LiteralClient()\n",
    "literal_client.instrument_openai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c110083-278b-4abf-9f2c-439cb550e338",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_NAME = \"RAG prompt\"\n",
    "template_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a helpful assistant that always answers questions. Keep it short, and if available prefer responding with code.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Answer the question based on the context below.\\nContext:\\n{{#context}}\\n{{.}}\\n{{/context}}\\nQuestion:\\n{{question}}\\nAnswer:\"\n",
    "    }\n",
    "]\n",
    "\n",
    "prompt = literal_client.api.create_prompt(name=PROMPT_NAME, template_messages=template_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cc23807-af1b-4c1c-a939-9aa277e72466",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to send steps: [Errno 111] Connection refused\n",
      "Failed to send steps: [Errno 111] Connection refused\n",
      "Failed to upsert thread: [Errno 111] Connection refused\n",
      "Failed to send steps: [Errno 111] Connection refused\n",
      "Failed to send steps: [Errno 111] Connection refused\n",
      "Failed to send steps: [Errno 111] Connection refused\n",
      "Failed to send steps: [Errno 111] Connection refused\n",
      "Failed to send steps: [Errno 111] Connection refused\n",
      "Failed to send steps: [Errno 111] Connection refused\n",
      "Failed to upsert thread: [Errno 111] Connection refused\n",
      "Failed to send steps: [Errno 111] Connection refused\n",
      "Failed to send steps: [Errno 111] Connection refused\n",
      "Failed to send steps: [Errno 111] Connection refused\n",
      "Failed to send steps: [Errno 111] Connection refused\n",
      "Failed to send steps: [Errno 111] Connection refused\n",
      "Failed to send steps: [Errno 111] Connection refused\n",
      "Failed to send steps: [Errno 111] Connection refused\n",
      "Failed to send steps: [Errno 111] Connection refused\n",
      "Failed to send steps: [Errno 111] Connection refused\n",
      "Failed to upsert thread: [Errno 111] Connection refused\n",
      "Failed to send steps: [Errno 111] Connection refused\n",
      "Failed to send steps: [Errno 111] Connection refused\n",
      "Failed to send steps: [Errno 111] Connection refused\n",
      "Failed to send steps: [Errno 111] Connection refused\n",
      "Failed to send steps: [Errno 111] Connection refused\n",
      "Failed to send steps: [Errno 111] Connection refused\n",
      "Failed to send steps: [Errno 111] Connection refused\n",
      "Failed to upsert thread: [Errno 111] Connection refused\n",
      "Failed to send steps: [Errno 111] Connection refused\n",
      "Failed to send steps: [Errno 111] Connection refused\n",
      "Failed to send steps: [Errno 111] Connection refused\n",
      "Failed to send steps: [Errno 111] Connection refused\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.299527883529663\n"
     ]
    }
   ],
   "source": [
    "@literal_client.step(type=\"run\", name=\"RAG\")\n",
    "def rag(user_query: str):\n",
    "    with literal_client.step(type=\"retrieval\", name=\"Retrieve\") as step:\n",
    "        step.input = { \"question\": user_query }\n",
    "        results = collection.query(query_texts=[user_query], n_results=2)\n",
    "        # time.sleep(1)\n",
    "        step.output = results\n",
    "\n",
    "    messages = prompt.format({\"context\": results[\"documents\"][0], \"question\": user_query})\n",
    "    \n",
    "    return \"Something\"\n",
    "        \n",
    "def main(cnt):\n",
    "    questions = [ \"What's my name?\", \"What's my job?\" ]\n",
    "    for idx, question in enumerate(questions[:1]):\n",
    "        with literal_client.thread(name=f\"Question {cnt} - {idx+1}\") as thread:\n",
    "            literal_client.message(content=question, type=\"user_message\", name=\"User\")\n",
    "            answer = rag(question)\n",
    "            time.sleep(1)\n",
    "            literal_client.message(content=answer, type=\"assistant_message\", name=\"My Assistant\")\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "cnt = 0\n",
    "while cnt < 10:\n",
    "    main(cnt)\n",
    "    cnt += 1\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Time elapsed {end-start}\")\n",
    "# Network requests by the SDK are performed asynchronously.\n",
    "# Invoke flush() to guarantee the completion of all requests prior to the process termination.\n",
    "# WARNING: If you run a continuous server, you should not use this method.\n",
    "literal_client.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ede3ee-ef76-48b7-9512-b3250f0bc610",
   "metadata": {},
   "source": [
    "#### Prepare Ragas data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9a25e08-3e9a-4466-82ca-e598743df1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from literalai import DatasetItem\n",
    "from typing import List\n",
    "\n",
    "items = dataset.items\n",
    "\n",
    "# Get the retrieved contexts for each question.\n",
    "contexts = []\n",
    "for item in items:\n",
    "    retrieve_step = next(step for step in item.intermediary_steps if step[\"name\"] == \"Retrieve\")\n",
    "    contexts.append(retrieve_step[\"expectedOutput\"][\"documents\"][0])\n",
    "\n",
    "# Data samples, in the format expected by Ragas. No ground truth needed since we will evaluate context relevancy.\n",
    "data_samples = {\n",
    "    'question': [item.input[\"args\"][0] for item in items],\n",
    "    'answer': [item.expected_output[\"content\"] for item in items],\n",
    "    'contexts': contexts,\n",
    "    'ground_truth': [\"\"]* len(items)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcda447e-4478-4a79-be74-3c36c46e29b1",
   "metadata": {},
   "source": [
    "#### Run the evaluation\n",
    "\n",
    "We will evaluate context relevancy which checks how relevant the retrieved contexts are to answer the user's question. \n",
    "\n",
    "The more unneeded details in the contexts, the less relevant (between 0 and 1, 0 being least relevant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e6b662b-7126-4a92-9703-45db0d49557c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "279e58f4240f439bbcb655f37272927f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import context_relevancy\n",
    "\n",
    "results = evaluate(Dataset.from_dict(data_samples), metrics=[context_relevancy]).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149b8c87-25c1-4a95-a593-aaa906f8a17f",
   "metadata": {},
   "source": [
    "### Persist experiment to Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4d02921-65c2-4f79-9ba1-464a08e6bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = dataset.create_experiment(\n",
    "    name=\"Biography - Experiment A\",\n",
    "    prompt_id=prompt.id,\n",
    "    params=[{ \"type\": context_relevancy.name, \"top_k\": 2 }]\n",
    ")\n",
    "\n",
    "# Log each experiment result.\n",
    "for index, row in results.iterrows():\n",
    "    scores = [{ \n",
    "        \"name\": context_relevancy.name,\n",
    "        \"type\": \"AI\",\n",
    "        \"value\": row[context_relevancy.name]\n",
    "    }]\n",
    "\n",
    "    experiment_item = {\n",
    "        \"datasetItemId\": items[index].id,\n",
    "        \"scores\": scores,\n",
    "        \"input\": { \"question\": row[\"question\"] },\n",
    "        \"output\": { \"contexts\": row[\"contexts\"].tolist() }\n",
    "    }\n",
    "    \n",
    "    experiment.log(experiment_item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
