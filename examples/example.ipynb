{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "862f5c24-824e-4100-8410-dd43f045d6e0",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "1. Make a copy of `../.env.example` to `../.env` and fill the `OPENAI_API_KEY` and `CHAINLIT_API_KEY` environment variables.\n",
    "2. This demo assumes that chainlit-cloud is running locally.\n",
    "3. Run the cells to install the dependencies and the local sdk package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c468a8c9-0197-437a-b1af-9e9816cb6d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5a8be8-2c72-4f09-8ab4-578dfe25829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -e .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ba337e-7db9-4810-ac7c-dd6532361f31",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04432a3b-22c6-4366-9521-7da36abd7106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "\n",
    "from chainlit_client import ChainlitClient\n",
    "from chainlit_client.types import Attachment\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from requests import get\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "sdk = ChainlitClient(batch_size=2)\n",
    "sdk.instrument_openai()\n",
    "\n",
    "thread_id = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@sdk.step(type=\"RUN\")\n",
    "def get_completion(welcome_message, text, temperature):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"Tell an inspiring quote to the user, mentioning their name. Be extremely supportive while keeping it short. Write one sentence per line. The current temperature is {temperature}Â°C.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": welcome_message,\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": text,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "current_weather_paris = \"https://api.open-meteo.com/v1/meteofrance?latitude=48.8588475&longitude=2.3058359&hourly=temperature_2m,relative_humidity_2m&forecast_days=1\"\n",
    "\n",
    "@sdk.thread\n",
    "def run():\n",
    "    global thread_id\n",
    "    thread_id = sdk.get_current_thread_id()\n",
    "\n",
    "    welcome_message = \"What's your name? \"\n",
    "    sdk.event(message=welcome_message, role=\"SYSTEM\")\n",
    "    text = input(welcome_message)\n",
    "    sdk.event(message=text, role=\"USER\")\n",
    "\n",
    "    with sdk.step(type=\"TOOL\") as step:\n",
    "        import datetime\n",
    "        res = get(current_weather_paris)\n",
    "        json = res.json()\n",
    "\n",
    "        current_time = datetime.datetime.now().strftime(\"%Y-%m-%dT%H:00\")\n",
    "        index = json[\"hourly\"][\"time\"].index(current_time)\n",
    "        temperature = json['hourly']['temperature_2m'][index]\n",
    "\n",
    "        completion = get_completion(welcome_message=welcome_message, text=text, temperature=temperature)\n",
    "\n",
    "    print(\"\")\n",
    "    print(completion)\n",
    "    sdk.event(message=completion, role=\"ASSISTANT\")\n",
    "        \n",
    "\n",
    "run()\n",
    "sdk.wait_until_queue_empty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the API to count the conversations in this project\n",
    "# and add feedback to the LLM step of the current conversation\n",
    "\n",
    "async def main():\n",
    "    threads = await sdk.api.list_threads()\n",
    "    print(threads[\"data\"][\"threads\"][\"totalCount\"], \"threads\")\n",
    "\n",
    "    print(\"\\nSearching for the thread\", thread_id, \"...\")\n",
    "    thread = await sdk.api.get_thread(id=thread_id)\n",
    "\n",
    "    print(json.dumps(thread.to_dict(), indent=2))\n",
    "\n",
    "    # get the LLM step\n",
    "    llm_step = [step for step in thread.steps if step.type == \"LLM\"][0]\n",
    "\n",
    "    if not llm_step:\n",
    "        print(\"Error: No LLM step found\")\n",
    "        return\n",
    "\n",
    "    # attach a feedback\n",
    "    await sdk.api.set_human_feedback(\n",
    "        thread_id=thread_id, step_id=llm_step.id, value=1, comment=\"this was accurate\"\n",
    "    )\n",
    "\n",
    "    # get the updated steps\n",
    "    thread = await sdk.api.get_thread(id=thread_id)\n",
    "\n",
    "    print(\n",
    "        json.dumps(\n",
    "            [step.to_dict() for step in thread.steps if step.type == \"LLM\"],\n",
    "            indent=2,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
